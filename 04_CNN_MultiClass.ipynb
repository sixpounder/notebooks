{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import urllib.request\n",
    "from os.path import exists\n",
    "\n",
    "if (not exists(\"./datasets/10_food_classes_all_data.zip\")):\n",
    "    print(\"Downloading archive...\")\n",
    "    urllib.request.urlretrieve(\"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\", \"./datasets/10_food_classes_all_data.zip\")\n",
    "else:\n",
    "    print(\"Archive already downloaded, unzipping...\")\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"datasets/10_food_classes_all_data.zip\")\n",
    "zip_ref.extractall(\"./datasets\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Walk thru 10 classes of food image data\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(\"datasets/10_food_classes_all_data\"):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup train and test directories\n",
    "\n",
    "train_dir = \"datasets/10_food_classes_all_data/train/\"\n",
    "test_dir = \"datasets/10_food_classes_all_data/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the subdirectories (the class names)\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "data_dir = pathlib.Path(train_dir)\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")]))\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "\n",
    "from image import view_random_image\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cls = random.choice(class_names)\n",
    "img = view_random_image(target_dir=train_dir, target_class=cls)\n",
    "plt.imshow(img)\n",
    "plt.axis(False)\n",
    "plt.title(f\"{cls} {img.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(train_dir, target_size=(244, 244), batch_size=32, class_mode=\"categorical\")\n",
    "test_data = train_datagen.flow_from_directory(test_dir, target_size=(244, 244), batch_size=32, class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPool2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model_1 = Sequential([\n",
    "    Conv2D(10, 3, activation=\"relu\", input_shape=(244, 244, 3)),\n",
    "    Conv2D(10, 3, activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(10, 3, activation=\"relu\"),\n",
    "    Conv2D(10, 3, activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(10, activation=\"softmax\") # Softmax for multi class problem\n",
    "])\n",
    "\n",
    "model_1.compile(loss=CategoricalCrossentropy(), metrics=[\"accuracy\"], optimizer=Adam())\n",
    "\n",
    "history_1 = model_1.fit(train_data, epochs=5, steps_per_epoch=len(train_data), validation_data=test_data, validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import plot_loss_curve\n",
    "\n",
    "plot_loss_curve(history_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's shit right now because it is overfitting the train data. Improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin by shuffling train and test sets\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(train_dir, target_size=(244, 244), batch_size=32, class_mode=\"categorical\", shuffle=True)\n",
    "test_data = train_datagen.flow_from_directory(test_dir, target_size=(244, 244), batch_size=32, class_mode=\"categorical\", shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify the model\n",
    "\n",
    "# Create a baseline\n",
    "\n",
    "model_2 = Sequential([\n",
    "    Conv2D(10, 3, activation=\"relu\", input_shape=(244, 244, 3)),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(10, 3, activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(10, activation=\"softmax\") # Softmax for multi class problem\n",
    "])\n",
    "\n",
    "model_2.compile(loss=CategoricalCrossentropy(), metrics=[\"accuracy\"], optimizer=Adam())\n",
    "\n",
    "history_2 = model_2.fit(train_data, epochs=5, steps_per_epoch=len(train_data), validation_data=test_data, validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still shit and still overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_data_augmented = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(244, 244),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "test_data_augmented = train_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(244, 244),\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPool2D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "model_3 = Sequential([\n",
    "    Conv2D(10, 3, activation=\"relu\", input_shape=(244, 244, 3)),\n",
    "    MaxPool2D(),\n",
    "    Conv2D(10, 3, activation=\"relu\"),\n",
    "    MaxPool2D(),\n",
    "    Flatten(),\n",
    "    Dense(10, activation=\"softmax\") # Softmax for multi class problem\n",
    "])\n",
    "model_3.compile(loss=CategoricalCrossentropy(), metrics=[\"accuracy\"], optimizer=Adam())\n",
    "\n",
    "model_3.fit(\n",
    "    train_data_augmented,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=len(train_data_augmented),\n",
    "    validation_data=test_data,\n",
    "    validation_steps=len(test_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.evaluate(test_data_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
